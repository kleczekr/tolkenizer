{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "foxbook_hierarchical_clustering.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMLk/TCcqnSFqhcNeIBRlhK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleczekr/tolkenizer/blob/master/foxbook_hierarchical_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yxZ-9MSW-Ng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.cluster import KMeansClusterer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNcEm3yNcvLL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HierarchicalClusters(object):\n",
        "  def __init__(self):\n",
        "    self.model = AgglomerativeClustering()\n",
        "  def fit(self, documents, labels=None):\n",
        "    return self\n",
        "  def transform(self, documents):\n",
        "    '''\n",
        "    fits the agglomerative model to the given data\n",
        "    '''\n",
        "    clusters = self.model.fit_predict(documents)\n",
        "    self.labels = self.model.labels_\n",
        "    self.children = self.model.children_\n",
        "    return clusters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qnDF1EedXkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextNormalizer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, language='english'):\n",
        "    self.stopwords = set(nltk.corpus.stopwords.words(language))\n",
        "    self.lemmatizer = WordNetLemmatizer()\n",
        "  def is_punct(self, token):\n",
        "    return all(unicodedata.category(char).startswith('P') for char in token)\n",
        "  def is_stopword(self, token):\n",
        "    return token.lower() in self.stopwords\n",
        "  def normalize(self, document):\n",
        "    return [\n",
        "            self.lemmatize(token, tag).lower()\n",
        "            for paragraph in document\n",
        "            for sentence in paragraph\n",
        "            for (token, tag) in sentence\n",
        "            if not self.is_punct(token) and not self.is_stopword(token)\n",
        "    ]\n",
        "  def lemmatize(self, token, pos_tag):\n",
        "    tag = {\n",
        "        'N': wn.NOUN,\n",
        "        'V': wn.VERB,\n",
        "        'R': wn.ADV,\n",
        "        'J': wn.ADJ\n",
        "    }.get(pos_tag[0], wn.NOUN)\n",
        "    return self.lemmatizer.lemmatize(token, tag)\n",
        "  def fit(self, X, y=None):\n",
        "    return self\n",
        "  def transform(self, documents):\n",
        "    return [' '.join(self.normalize(doc)) for doc in documents]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLjawkYIdXhX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class OneHotVectorizer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self):\n",
        "    self.vectorizer = CountVectorizer(binary=True)\n",
        "  def fit(self, documents, labels=None):\n",
        "    return self\n",
        "  def transform(self, documents):\n",
        "    freqs = self.vectorizer.fit_transform(documents)\n",
        "    return [freq.toarray()[0] for freq in freqs]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERJOCOkpdXen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = PickledCorpusReader('../corpus')\n",
        "docs = corpus.docs(categories=['news'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcFGWWPxdmlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Pipeline([\n",
        "                  ('norm', TextNormalizer()),\n",
        "                  ('vect', OneHotVectorizer()),\n",
        "                  ('clusters', HierarchicalClusters())\n",
        "])\n",
        "\n",
        "model.fit_transform(docs)\n",
        "labels = model.named_steps['clusters'].labels\n",
        "pickles = list(corpus.fileids(categories=['news']))\n",
        "\n",
        "for idx, fileid in enumerate(pickles):\n",
        "  print('Document \"{}\" assigned to cluster {}.'.format(fileid, labels[idx]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_U4Pq1WgeUPF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RzQkbZ9eez8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_dendrogram(children, **kwargs):\n",
        "  # distances btw each pair of children\n",
        "  distance = position = np.arrange(children.shape[0])\n",
        "\n",
        "  # create linkage matrix and then plot the dendrogram\n",
        "  linkage_matrix = np.column_stack([\n",
        "                                    children, distance, position\n",
        "  ]).astype(float)\n",
        "\n",
        "  # plot the corresponding dendrogram\n",
        "  fig, ax = plt.subplots(figsize=(10, 5)) # set size\n",
        "  ax = dendrogram(linkage_matrix, **kwargs)\n",
        "  plt.tick_params(axis='x', bottom='off', top='off', labelbottom='off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNwdRXRufa0c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "children = model.named_steps['clusters'].children\n",
        "plot_dendrogram(children)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}