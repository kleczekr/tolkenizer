{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "courage_daring_clustering_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMD7J3zf5L2XlilABfvxnPc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleczekr/tolkenizer/blob/master/courage_daring_clustering_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mM7Z75m0EX0-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5bc18bee-354b-4065-e2ab-f2f1872b8ab0"
      },
      "source": [
        "import nltk.data\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "from urllib import request"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tig2SutSjFA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_alice = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
        "url_moby = 'https://www.gutenberg.org/files/2701/2701-0.txt'\n",
        "# opening the txt files\n",
        "response_alice = request.urlopen(url_alice)\n",
        "response_moby = request.urlopen(url_moby)\n",
        "# reading the files into raw variables as strings\n",
        "raw_alice = response_alice.read().decode('utf8')\n",
        "raw_moby = response_moby.read().decode('utf8')\n",
        "# Split the raw files into lists of sentences\n",
        "tokenized_alice = sent_tokenize(raw_alice)\n",
        "tokenized_moby = sent_tokenize(raw_moby)\n",
        "# remove the contents\n",
        "tokenized_alice = tokenized_alice[14:]\n",
        "tokenized_moby = tokenized_moby[275:]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a61dk5MSSw30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # split sentences into lists of words\n",
        "# def sent_list_splitter(list_of_sentences):\n",
        "#   for sentence in list_of_sentences:\n",
        "#     sentence = sentence.split()\n",
        "#     word = [word.lower() for word in sentence]\n",
        "#     return sentence"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgqGyiuBUVvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split sentences into lists of words\n",
        "word_split_alice = [sentence.split() for sentence in tokenized_alice]\n",
        "word_split_moby = [sentence.split() for sentence in tokenized_moby]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyBn_lUpUdGv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "18d67830-7795-4bdb-9fd5-87452e63d835"
      },
      "source": [
        "for sentence in word_split_alice[100:120]:\n",
        "  print(sentence)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ever', 'so', 'many', 'lessons', 'to', 'learn!']\n",
            "['No,', 'I’ve', 'made', 'up', 'my', 'mind', 'about', 'it;', 'if', 'I’m', 'Mabel,', 'I’ll', 'stay', 'down', 'here!']\n",
            "['It’ll', 'be', 'no', 'use', 'their', 'putting', 'their', 'heads', 'down', 'and', 'saying', '‘Come', 'up', 'again,', 'dear!’', 'I', 'shall', 'only', 'look', 'up', 'and', 'say', '‘Who', 'am', 'I', 'then?']\n",
            "['Tell', 'me', 'that', 'first,', 'and', 'then,', 'if', 'I', 'like', 'being', 'that', 'person,', 'I’ll', 'come', 'up:', 'if', 'not,', 'I’ll', 'stay', 'down', 'here', 'till', 'I’m', 'somebody', 'else’—but,', 'oh', 'dear!”', 'cried', 'Alice,', 'with', 'a', 'sudden', 'burst', 'of', 'tears,', '“I', 'do', 'wish', 'they', '_would_', 'put', 'their', 'heads', 'down!']\n",
            "['I', 'am', 'so', '_very_', 'tired', 'of', 'being', 'all', 'alone', 'here!”', 'As', 'she', 'said', 'this', 'she', 'looked', 'down', 'at', 'her', 'hands,', 'and', 'was', 'surprised', 'to', 'see', 'that', 'she', 'had', 'put', 'on', 'one', 'of', 'the', 'Rabbit’s', 'little', 'white', 'kid', 'gloves', 'while', 'she', 'was', 'talking.']\n",
            "['“How', '_can_', 'I', 'have', 'done', 'that?”', 'she', 'thought.']\n",
            "['“I', 'must', 'be', 'growing', 'small', 'again.”', 'She', 'got', 'up', 'and', 'went', 'to', 'the', 'table', 'to', 'measure', 'herself', 'by', 'it,', 'and', 'found', 'that,', 'as', 'nearly', 'as', 'she', 'could', 'guess,', 'she', 'was', 'now', 'about', 'two', 'feet', 'high,', 'and', 'was', 'going', 'on', 'shrinking', 'rapidly:', 'she', 'soon', 'found', 'out', 'that', 'the', 'cause', 'of', 'this', 'was', 'the', 'fan', 'she', 'was', 'holding,', 'and', 'she', 'dropped', 'it', 'hastily,', 'just', 'in', 'time', 'to', 'avoid', 'shrinking', 'away', 'altogether.']\n",
            "['“That', '_was_', 'a', 'narrow', 'escape!”', 'said', 'Alice,', 'a', 'good', 'deal', 'frightened', 'at', 'the', 'sudden', 'change,', 'but', 'very', 'glad', 'to', 'find', 'herself', 'still', 'in', 'existence;', '“and', 'now', 'for', 'the', 'garden!”', 'and', 'she', 'ran', 'with', 'all', 'speed', 'back', 'to', 'the', 'little', 'door:', 'but,', 'alas!']\n",
            "['the', 'little', 'door', 'was', 'shut', 'again,', 'and', 'the', 'little', 'golden', 'key', 'was', 'lying', 'on', 'the', 'glass', 'table', 'as', 'before,', '“and', 'things', 'are', 'worse', 'than', 'ever,”', 'thought', 'the', 'poor', 'child,', '“for', 'I', 'never', 'was', 'so', 'small', 'as', 'this', 'before,', 'never!']\n",
            "['And', 'I', 'declare', 'it’s', 'too', 'bad,', 'that', 'it', 'is!”', 'As', 'she', 'said', 'these', 'words', 'her', 'foot', 'slipped,', 'and', 'in', 'another', 'moment,', 'splash!']\n",
            "['she', 'was', 'up', 'to', 'her', 'chin', 'in', 'salt', 'water.']\n",
            "['Her', 'first', 'idea', 'was', 'that', 'she', 'had', 'somehow', 'fallen', 'into', 'the', 'sea,', '“and', 'in', 'that', 'case', 'I', 'can', 'go', 'back', 'by', 'railway,”', 'she', 'said', 'to', 'herself.']\n",
            "['(Alice', 'had', 'been', 'to', 'the', 'seaside', 'once', 'in', 'her', 'life,', 'and', 'had', 'come', 'to', 'the', 'general', 'conclusion,', 'that', 'wherever', 'you', 'go', 'to', 'on', 'the', 'English', 'coast', 'you', 'find', 'a', 'number', 'of', 'bathing', 'machines', 'in', 'the', 'sea,', 'some', 'children', 'digging', 'in', 'the', 'sand', 'with', 'wooden', 'spades,', 'then', 'a', 'row', 'of', 'lodging', 'houses,', 'and', 'behind', 'them', 'a', 'railway', 'station.)']\n",
            "['However,', 'she', 'soon', 'made', 'out', 'that', 'she', 'was', 'in', 'the', 'pool', 'of', 'tears', 'which', 'she', 'had', 'wept', 'when', 'she', 'was', 'nine', 'feet', 'high.']\n",
            "['“I', 'wish', 'I', 'hadn’t', 'cried', 'so', 'much!”', 'said', 'Alice,', 'as', 'she', 'swam', 'about,', 'trying', 'to', 'find', 'her', 'way', 'out.']\n",
            "['“I', 'shall', 'be', 'punished', 'for', 'it', 'now,', 'I', 'suppose,', 'by', 'being', 'drowned', 'in', 'my', 'own', 'tears!']\n",
            "['That', '_will_', 'be', 'a', 'queer', 'thing,', 'to', 'be', 'sure!']\n",
            "['However,', 'everything', 'is', 'queer', 'to-day.”', 'Just', 'then', 'she', 'heard', 'something', 'splashing', 'about', 'in', 'the', 'pool', 'a', 'little', 'way', 'off,', 'and', 'she', 'swam', 'nearer', 'to', 'make', 'out', 'what', 'it', 'was:', 'at', 'first', 'she', 'thought', 'it', 'must', 'be', 'a', 'walrus', 'or', 'hippopotamus,', 'but', 'then', 'she', 'remembered', 'how', 'small', 'she', 'was', 'now,', 'and', 'she', 'soon', 'made', 'out', 'that', 'it', 'was', 'only', 'a', 'mouse', 'that', 'had', 'slipped', 'in', 'like', 'herself.']\n",
            "['“Would', 'it', 'be', 'of', 'any', 'use,', 'now,”', 'thought', 'Alice,', '“to', 'speak', 'to', 'this', 'mouse?']\n",
            "['Everything', 'is', 'so', 'out-of-the-way', 'down', 'here,', 'that', 'I', 'should', 'think', 'very', 'likely', 'it', 'can', 'talk:', 'at', 'any', 'rate,', 'there’s', 'no', 'harm', 'in', 'trying.”', 'So', 'she', 'began:', '“O', 'Mouse,', 'do', 'you', 'know', 'the', 'way', 'out', 'of', 'this', 'pool?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to40E_RNUohK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "13118b6c-4d42-4a77-b180-02deb4cf6f38"
      },
      "source": [
        "for sentence in word_split_moby[100:120]:\n",
        "  print(sentence)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Hist_.']\n",
            "['“If', 'you', 'should', 'write', 'a', 'fable', 'for', 'little', 'fishes,', 'you', 'would', 'make', 'them', 'speak', 'like', 'great', 'whales.”', '—_Goldsmith', 'to', 'Johnson_.']\n",
            "['“In', 'the', 'afternoon', 'we', 'saw', 'what', 'was', 'supposed', 'to', 'be', 'a', 'rock,', 'but', 'it', 'was', 'found', 'to', 'be', 'a', 'dead', 'whale,', 'which', 'some', 'Asiatics', 'had', 'killed,', 'and', 'were', 'then', 'towing', 'ashore.']\n",
            "['They', 'seemed', 'to', 'endeavor', 'to', 'conceal', 'themselves', 'behind', 'the', 'whale,', 'in', 'order', 'to', 'avoid', 'being', 'seen', 'by', 'us.”', '—_Cook’s', 'Voyages_.']\n",
            "['“The', 'larger', 'whales,', 'they', 'seldom', 'venture', 'to', 'attack.']\n",
            "['They', 'stand', 'in', 'so', 'great', 'dread', 'of', 'some', 'of', 'them,', 'that', 'when', 'out', 'at', 'sea', 'they', 'are', 'afraid', 'to', 'mention', 'even', 'their', 'names,', 'and', 'carry', 'dung,', 'lime-stone,', 'juniper-wood,', 'and', 'some', 'other', 'articles', 'of', 'the', 'same', 'nature', 'in', 'their', 'boats,', 'in', 'order', 'to', 'terrify', 'and', 'prevent', 'their', 'too', 'near', 'approach.”', '—_Uno', 'Von', 'Troil’s', 'Letters', 'on', 'Banks’s', 'and', 'Solander’s', 'Voyage', 'to', 'Iceland', 'in_', '1772.']\n",
            "['“The', 'Spermacetti', 'Whale', 'found', 'by', 'the', 'Nantuckois,', 'is', 'an', 'active,', 'fierce', 'animal,', 'and', 'requires', 'vast', 'address', 'and', 'boldness', 'in', 'the', 'fishermen.”', '—_Thomas', 'Jefferson’s', 'Whale', 'Memorial', 'to', 'the', 'French', 'minister', 'in_', '1778.']\n",
            "['“And', 'pray,', 'sir,', 'what', 'in', 'the', 'world', 'is', 'equal', 'to', 'it?”', '—_Edmund', 'Burke’s', 'reference', 'in', 'Parliament', 'to', 'the', 'Nantucket', 'Whale-Fishery_.']\n",
            "['“Spain—a', 'great', 'whale', 'stranded', 'on', 'the', 'shores', 'of', 'Europe.”', '—_Edmund', 'Burke_.']\n",
            "['(_somewhere_.)']\n",
            "['“A', 'tenth', 'branch', 'of', 'the', 'king’s', 'ordinary', 'revenue,', 'said', 'to', 'be', 'grounded', 'on', 'the', 'consideration', 'of', 'his', 'guarding', 'and', 'protecting', 'the', 'seas', 'from', 'pirates', 'and', 'robbers,', 'is', 'the', 'right', 'to', '_royal_', 'fish,', 'which', 'are', 'whale', 'and', 'sturgeon.']\n",
            "['And', 'these,', 'when', 'either', 'thrown', 'ashore', 'or', 'caught', 'near', 'the', 'coast,', 'are', 'the', 'property', 'of', 'the', 'king.”', '—_Blackstone_.']\n",
            "['“Soon', 'to', 'the', 'sport', 'of', 'death', 'the', 'crews', 'repair:', 'Rodmond', 'unerring', 'o’er', 'his', 'head', 'suspends', 'The', 'barbed', 'steel,', 'and', 'every', 'turn', 'attends.”', '—_Falconer’s', 'Shipwreck_.']\n",
            "['“Bright', 'shone', 'the', 'roofs,', 'the', 'domes,', 'the', 'spires,', 'And', 'rockets', 'blew', 'self', 'driven,', 'To', 'hang', 'their', 'momentary', 'fire', 'Around', 'the', 'vault', 'of', 'heaven.']\n",
            "['“So', 'fire', 'with', 'water', 'to', 'compare,', 'The', 'ocean', 'serves', 'on', 'high,', 'Up-spouted', 'by', 'a', 'whale', 'in', 'air,', 'To', 'express', 'unwieldy', 'joy.”', '—_Cowper,', 'on', 'the', 'Queen’s', 'Visit', 'to', 'London_.']\n",
            "['“Ten', 'or', 'fifteen', 'gallons', 'of', 'blood', 'are', 'thrown', 'out', 'of', 'the', 'heart', 'at', 'a', 'stroke,', 'with', 'immense', 'velocity.”', '—_John', 'Hunter’s', 'account', 'of', 'the', 'dissection', 'of', 'a', 'whale_.']\n",
            "['(_A', 'small', 'sized', 'one_.)']\n",
            "['“The', 'aorta', 'of', 'a', 'whale', 'is', 'larger', 'in', 'the', 'bore', 'than', 'the', 'main', 'pipe', 'of', 'the', 'water-works', 'at', 'London', 'Bridge,', 'and', 'the', 'water', 'roaring', 'in', 'its', 'passage', 'through', 'that', 'pipe', 'is', 'inferior', 'in', 'impetus', 'and', 'velocity', 'to', 'the', 'blood', 'gushing', 'from', 'the', 'whale’s', 'heart.”', '—_Paley’s', 'Theology_.']\n",
            "['“The', 'whale', 'is', 'a', 'mammiferous', 'animal', 'without', 'hind', 'feet.”', '—_Baron', 'Cuvier_.']\n",
            "['“In', '40', 'degrees', 'south,', 'we', 'saw', 'Spermacetti', 'Whales,', 'but', 'did', 'not', 'take', 'any', 'till', 'the', 'first', 'of', 'May,', 'the', 'sea', 'being', 'then', 'covered', 'with', 'them.”', '—_Colnett’s', 'Voyage', 'for', 'the', 'Purpose', 'of', 'Extending', 'the', 'Spermaceti', 'Whale', 'Fishery_.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLT2mGKrZ0Kb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_split_joint = word_split_alice + word_split_moby"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ2OIT1IbVj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# clustering!\n",
        "# from gensim.models import Word2Vec\n",
        "# import nltk\n",
        "# import numpy as np\n",
        "# from sklearn.cluster import KMeans\n",
        "# from sklearn import cluster\n",
        "# from sklearn import metrics\n",
        "# from sklearn.decomposition import PCA\n",
        "# from scipy.cluster import hierarchy\n",
        "# from sklearn.cluster import AgglomerativeClustering"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}