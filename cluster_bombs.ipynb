{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cluster_bombs.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJWrZsSfQajuB9kFJMjpKa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleczekr/tolkenizer/blob/master/cluster_bombs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sn-vpXHqKn3E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "015e95e8-30e2-481a-ed61-2dc1157c7a04"
      },
      "source": [
        "import nltk.data\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "from urllib import request\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "#from sklearn.cluster import KMeans\n",
        "#from sklearn.metrics import adjusted_rand_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDt-_VM4LNoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_alice = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
        "url_moby = 'https://www.gutenberg.org/files/2701/2701-0.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh16EWFmL6oM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# opening the txt files\n",
        "response_alice = request.urlopen(url_alice)\n",
        "response_moby = request.urlopen(url_moby)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LUA6MMGL8K2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reading the files into raw variables as strings\n",
        "raw_alice = response_alice.read().decode('utf8')\n",
        "raw_moby = response_moby.read().decode('utf8')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dD8MjHOMT5x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9625e9d5-9098-4a36-a6c6-4e6c01bf83e2"
      },
      "source": [
        "print('The text of \"Alice...\" is {} characters long, that of \"Moby...\" is {} characters long.'.format(len(raw_alice), len(raw_moby)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The text of \"Alice...\" is 167975 characters long, that of \"Moby...\" is 1260577 characters long.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3u8CEUXMkgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ec37a83-266d-4bd5-f27f-bd579e20bc16"
      },
      "source": [
        "moby_rel_alice = len(raw_moby) - len(raw_alice)\n",
        "print('The text of \"Moby...\" is {} characters longer than the text of \"Alice...\".'.format(moby_rel_alice))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The text of \"Moby...\" is 1092602 characters longer than the text of \"Alice...\".\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQm5PUu_Nx3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the raw files into lists of sentences\n",
        "tokenized_alice = sent_tokenize(raw_alice)\n",
        "tokenized_moby = sent_tokenize(raw_moby)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXgAFCEHPD6T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82841ec5-e3b9-4467-dc13-ce97d6d7ece1"
      },
      "source": [
        "print('Alice contains {} sentences, and Moby {}.'.format(len(tokenized_alice), len(tokenized_moby)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alice contains 1102 sentences, and Moby 9180.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoMqxNPxPcBG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "37f5e0c1-cedb-4793-dbbd-7c2fad5d5c18"
      },
      "source": [
        "tokenized_alice[9:16]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Mock Turtle’s Story\\r\\n CHAPTER X.',\n",
              " 'The Lobster Quadrille\\r\\n CHAPTER XI.',\n",
              " 'Who Stole the Tarts?',\n",
              " 'CHAPTER XII.',\n",
              " 'Alice’s Evidence\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nCHAPTER I.',\n",
              " 'Down the Rabbit-Hole\\r\\n\\r\\n\\r\\nAlice was beginning to get very tired of sitting by her sister on the\\r\\nbank, and of having nothing to do: once or twice she had peeped into\\r\\nthe book her sister was reading, but it had no pictures or\\r\\nconversations in it, “and what is the use of a book,” thought Alice\\r\\n“without pictures or conversations?”\\r\\n\\r\\nSo she was considering in her own mind (as well as she could, for the\\r\\nhot day made her feel very sleepy and stupid), whether the pleasure of\\r\\nmaking a daisy-chain would be worth the trouble of getting up and\\r\\npicking the daisies, when suddenly a White Rabbit with pink eyes ran\\r\\nclose by her.',\n",
              " 'There was nothing so _very_ remarkable in that; nor did Alice think it\\r\\nso _very_ much out of the way to hear the Rabbit say to itself, “Oh\\r\\ndear!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dHiZOiIoQeX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove the introduction and contents\n",
        "tokenized_alice = tokenized_alice[14:]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0jzyx6IPh6X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "1874ad9c-5960-48cb-a715-0c05e84d36b7"
      },
      "source": [
        "tokenized_moby[275:290]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Epilogue\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nOriginal Transcriber’s Notes:\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nThis text is a combination of etexts, one from the now-defunct ERIS\\r\\nproject at Virginia Tech and one from Project Gutenberg’s archives.',\n",
              " 'The\\r\\nproofreaders of this version are indebted to The University of Adelaide\\r\\nLibrary for preserving the Virginia Tech version.',\n",
              " 'The resulting etext\\r\\nwas compared with a public domain hard copy version of the text.',\n",
              " 'ETYMOLOGY.',\n",
              " '(Supplied by a Late Consumptive Usher to a Grammar School.)',\n",
              " 'The pale Usher—threadbare in coat, heart, body, and brain; I see him\\r\\n  now.',\n",
              " 'He was ever dusting his old lexicons and grammars, with a queer\\r\\n  handkerchief, mockingly embellished with all the gay flags of all the\\r\\n  known nations of the world.',\n",
              " 'He loved to dust his old grammars; it\\r\\n  somehow mildly reminded him of his mortality.',\n",
              " '“While you take in hand to school others, and to teach them by what\\r\\n  name a whale-fish is to be called in our tongue, leaving out, through\\r\\n  ignorance, the letter H, which almost alone maketh up the\\r\\n  signification of the word, you deliver that which is not true.”\\r\\n  —_Hackluyt._\\r\\n\\r\\n  “WHALE.',\n",
              " '* * * Sw. and Dan.',\n",
              " '_hval_.',\n",
              " 'This animal is named from\\r\\n  roundness or rolling; for in Dan.',\n",
              " '_hvalt_ is arched or vaulted.”\\r\\n  —_Webster’s Dictionary._\\r\\n\\r\\n  “WHALE.',\n",
              " '* * * It is more immediately from the Dut.',\n",
              " 'and Ger.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjvcmThTpEjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove the contents\n",
        "tokenized_moby = tokenized_moby[275:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCTqO_fmPuQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# join both lists of sentences\n",
        "tokenized_joined = tokenized_alice + tokenized_moby"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dptYYNLpRSPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # vectorize the combined list of sentences\n",
        "# vectorizer = TfidfVectorizer(stop_words='english')\n",
        "# X = vectorizer.fit_transform(tokenized_joined)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLR7Ra14Royo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# true_k = 2\n",
        "# model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
        "# model.fit(X)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Canii6F0Rz1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(\"Top terms per cluster:\")\n",
        "# order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
        "# terms = vectorizer.get_feature_names()\n",
        "# for i in range(true_k):\n",
        "#     print(\"Cluster %d:\" % i),\n",
        "#     for ind in order_centroids[i, :10]:\n",
        "#         print(' %s' % terms[ind]),\n",
        "#     print\n",
        "\n",
        "# print(\"\\n\")\n",
        "# print(\"Prediction\")\n",
        "\n",
        "# Y = vectorizer.transform([\"chrome browser to open.\"])\n",
        "# prediction = model.predict(Y)\n",
        "# print(prediction)\n",
        "\n",
        "# Y = vectorizer.transform([\"My cat is hungry.\"])\n",
        "# prediction = model.predict(Y)\n",
        "# print(prediction)"
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}