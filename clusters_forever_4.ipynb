{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clusters_forever_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOikPc0Eu9igiDLbW1SxOMg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kleczekr/tolkenizer/blob/master/clusters_forever_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tt58PX4nLl18",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "06d3921b-3f4f-47d0-ee19-c09034589946"
      },
      "source": [
        "import nltk.data\n",
        "from nltk.tokenize import sent_tokenize\n",
        "nltk.download('punkt')\n",
        "from urllib import request"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAvL20I-LtHk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url_alice = 'https://www.gutenberg.org/files/11/11-0.txt'\n",
        "url_moby = 'https://www.gutenberg.org/files/2701/2701-0.txt'\n",
        "# opening the txt files\n",
        "response_alice = request.urlopen(url_alice)\n",
        "response_moby = request.urlopen(url_moby)\n",
        "# reading the files into raw variables as strings\n",
        "raw_alice = response_alice.read().decode('utf8')\n",
        "raw_moby = response_moby.read().decode('utf8')\n",
        "# Split the raw files into lists of sentences\n",
        "tokenized_alice = sent_tokenize(raw_alice)\n",
        "tokenized_moby = sent_tokenize(raw_moby)\n",
        "# remove the contents\n",
        "tokenized_alice = tokenized_alice[14:]\n",
        "tokenized_moby = tokenized_moby[275:]\n",
        "# join the lists\n",
        "tokenized_joint = tokenized_alice + tokenized_moby\n",
        "# split joint list into lists of words\n",
        "word_split_joint = [sentence.split() for sentence in tokenized_joint]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31fFO0DeNSe4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "61b83e9a-1d63-42c3-f6b3-78d3164ee817"
      },
      "source": [
        "for sentence in word_split_joint[1000:1010]:\n",
        "  print(sentence)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['The', 'copyright', 'laws', 'of', 'the', 'place', 'where', 'you', 'are', 'located', 'also', 'govern', 'what', 'you', 'can', 'do', 'with', 'this', 'work.']\n",
            "['Copyright', 'laws', 'in', 'most', 'countries', 'are', 'in', 'a', 'constant', 'state', 'of', 'change.']\n",
            "['If', 'you', 'are', 'outside', 'the', 'United', 'States,', 'check', 'the', 'laws', 'of', 'your', 'country', 'in', 'addition', 'to', 'the', 'terms', 'of', 'this', 'agreement', 'before', 'downloading,', 'copying,', 'displaying,', 'performing,', 'distributing', 'or', 'creating', 'derivative', 'works', 'based', 'on', 'this', 'work', 'or', 'any', 'other', 'Project', 'Gutenberg-tm', 'work.']\n",
            "['The', 'Foundation', 'makes', 'no', 'representations', 'concerning', 'the', 'copyright', 'status', 'of', 'any', 'work', 'in', 'any', 'country', 'outside', 'the', 'United', 'States.']\n",
            "['1.E.']\n",
            "['Unless', 'you', 'have', 'removed', 'all', 'references', 'to', 'Project', 'Gutenberg:', '1.E.1.']\n",
            "['The', 'following', 'sentence,', 'with', 'active', 'links', 'to,', 'or', 'other', 'immediate', 'access', 'to,', 'the', 'full', 'Project', 'Gutenberg-tm', 'License', 'must', 'appear', 'prominently', 'whenever', 'any', 'copy', 'of', 'a', 'Project', 'Gutenberg-tm', 'work', '(any', 'work', 'on', 'which', 'the', 'phrase', '\"Project', 'Gutenberg\"', 'appears,', 'or', 'with', 'which', 'the', 'phrase', '\"Project', 'Gutenberg\"', 'is', 'associated)', 'is', 'accessed,', 'displayed,', 'performed,', 'viewed,', 'copied', 'or', 'distributed:', 'This', 'eBook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'in', 'the', 'United', 'States', 'and', 'most', 'other', 'parts', 'of', 'the', 'world', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever.']\n",
            "['You', 'may', 'copy', 'it,', 'give', 'it', 'away', 'or', 're-use', 'it', 'under', 'the', 'terms', 'of', 'the', 'Project', 'Gutenberg', 'License', 'included', 'with', 'this', 'eBook', 'or', 'online', 'at', 'www.gutenberg.org.']\n",
            "['If', 'you', 'are', 'not', 'located', 'in', 'the', 'United', 'States,', \"you'll\", 'have', 'to', 'check', 'the', 'laws', 'of', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using', 'this', 'ebook.']\n",
            "['1.E.2.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z55vOyJaL8vU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4143147f-059f-4ce7-9748-57d847449f23"
      },
      "source": [
        "# pipeline to clean the lists of words (remove uppercase,\n",
        "# punctuation, words are subsequently stemmed)\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "\n",
        "table = str.maketrans('', '', string.punctuation)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def fantabulize(sentence):\n",
        "  # lowercase\n",
        "  sentence = [word.lower() for word in sentence]\n",
        "  # remove punctuation\n",
        "  sentence = [word.translate(table) for word in sentence]\n",
        "  # remove nonalphabetic tokens\n",
        "  sentence = [word for word in sentence if word.isalpha()]\n",
        "  # remove stopwords\n",
        "  sentence = [word for word in sentence if not word in stop_words]\n",
        "  # stem em words\n",
        "  sentence = [porter.stem(word) for word in sentence]\n",
        "  # return em sentence\n",
        "  return sentence"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yYM6vZcNctn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# run the fantabulize pipeline on our list of lists of words\n",
        "count = 0\n",
        "for sentence in word_split_joint:\n",
        "  word_split_joint[count] = fantabulize(sentence)\n",
        "  count += 1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cwl7S7NpNuKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "39ab4b8c-6b4a-47ba-b920-9be9a03de08c"
      },
      "source": [
        "for sentence in word_split_joint[1000:1010]:\n",
        "  print(sentence)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['copyright', 'law', 'place', 'locat', 'also', 'govern', 'work']\n",
            "['copyright', 'law', 'countri', 'constant', 'state', 'chang']\n",
            "['outsid', 'unit', 'state', 'check', 'law', 'countri', 'addit', 'term', 'agreement', 'download', 'copi', 'display', 'perform', 'distribut', 'creat', 'deriv', 'work', 'base', 'work', 'project', 'gutenbergtm', 'work']\n",
            "['foundat', 'make', 'represent', 'concern', 'copyright', 'statu', 'work', 'countri', 'outsid', 'unit', 'state']\n",
            "[]\n",
            "['unless', 'remov', 'refer', 'project', 'gutenberg']\n",
            "['follow', 'sentenc', 'activ', 'link', 'immedi', 'access', 'full', 'project', 'gutenbergtm', 'licens', 'must', 'appear', 'promin', 'whenev', 'copi', 'project', 'gutenbergtm', 'work', 'work', 'phrase', 'project', 'gutenberg', 'appear', 'phrase', 'project', 'gutenberg', 'associ', 'access', 'display', 'perform', 'view', 'copi', 'distribut', 'ebook', 'use', 'anyon', 'anywher', 'unit', 'state', 'part', 'world', 'cost', 'almost', 'restrict', 'whatsoev']\n",
            "['may', 'copi', 'give', 'away', 'reus', 'term', 'project', 'gutenberg', 'licens', 'includ', 'ebook', 'onlin', 'wwwgutenbergorg']\n",
            "['locat', 'unit', 'state', 'youll', 'check', 'law', 'countri', 'locat', 'use', 'ebook']\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO4ls9muQ8Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# let's try removing empty lists:\n",
        "word_split_joint = [element for element in word_split_joint if element != []]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EkfoG4xRNYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "2bf8783c-d1e0-4d30-de80-8a37291b4caf"
      },
      "source": [
        "for sentence in word_split_joint[1000:1010]:\n",
        "  print(sentence)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['charg', 'fee', 'access', 'view', 'display', 'perform', 'copi', 'distribut', 'project', 'gutenbergtm', 'work', 'unless', 'compli', 'paragraph']\n",
            "['may', 'charg', 'reason', 'fee', 'copi', 'provid', 'access', 'distribut', 'project', 'gutenbergtm', 'electron', 'work', 'provid', 'pay', 'royalti', 'fee', 'gross', 'profit', 'deriv', 'use', 'project', 'gutenbergtm', 'work', 'calcul', 'use', 'method', 'alreadi', 'use', 'calcul', 'applic', 'tax']\n",
            "['fee', 'owe', 'owner', 'project', 'gutenbergtm', 'trademark', 'agre', 'donat', 'royalti', 'paragraph', 'project', 'gutenberg', 'literari', 'archiv', 'foundat']\n",
            "['royalti', 'payment', 'must', 'paid', 'within', 'day', 'follow', 'date', 'prepar', 'legal', 'requir', 'prepar', 'period', 'tax', 'return']\n",
            "['royalti', 'payment', 'clearli', 'mark', 'sent', 'project', 'gutenberg', 'literari', 'archiv', 'foundat', 'address', 'specifi', 'section', 'inform', 'donat', 'project', 'gutenberg', 'literari', 'archiv', 'foundat']\n",
            "['provid', 'full', 'refund', 'money', 'paid', 'user', 'notifi', 'write', 'email', 'within', 'day', 'receipt', 'agre', 'term', 'full', 'project', 'gutenbergtm', 'licens']\n",
            "['must', 'requir', 'user', 'return', 'destroy', 'copi', 'work', 'possess', 'physic', 'medium', 'discontinu', 'use', 'access', 'copi', 'project', 'gutenbergtm', 'work']\n",
            "['provid', 'accord', 'paragraph', 'full', 'refund', 'money', 'paid', 'work', 'replac', 'copi', 'defect', 'electron', 'work', 'discov', 'report', 'within', 'day', 'receipt', 'work']\n",
            "['compli', 'term', 'agreement', 'free', 'distribut', 'project', 'gutenbergtm', 'work']\n",
            "['wish', 'charg', 'fee', 'distribut', 'project', 'gutenbergtm', 'electron', 'work', 'group', 'work', 'differ', 'term', 'set', 'forth', 'agreement', 'must', 'obtain', 'permiss', 'write', 'project', 'gutenberg', 'literari', 'archiv', 'foundat', 'project', 'gutenberg', 'trademark', 'llc', 'owner', 'project', 'gutenbergtm', 'trademark']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBXbOXExLvem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26ed0bd0-8e3f-4639-bc25-2b7ccb7d5d05"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(word_split_joint, min_count=1)\n",
        "# summarize the loaded model\n",
        "print(model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=11827, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}